{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8014ee",
   "metadata": {
    "cell_style": "center",
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img align=\"left\" src=\"img/ECE364-logo.png\" width=\"300px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n",
    "# Lecture 0 - Course Intro and PyTorch Basics\n",
    "## ECE364 - Programming Methods for Machine Learning\n",
    "### Nickvash Kani \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Slides based off prior lectures by Alex Schwing, Aigou Han, Farzas Kamalabadi, Corey Snyder. All mistakes are my own!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3086c8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Topics covered: \n",
    "\n",
    "- Learning machine learning fundamentals including: \n",
    "    - linear algebra review\n",
    "    - automatic regression and classifcation fitting models\n",
    "    - building complex neural networks (deep models)\n",
    "\n",
    "- Learn the fundamentals of PyTorch for basic deep learning models\n",
    "    - efficient computation/storage\n",
    "    - computational graphs/back-propagation\n",
    "    - formatting data and training NN models\n",
    "    \n",
    "- Advanced machine learning topics\n",
    "    - advanced deep network concepts like attention (transformer models)\n",
    "    - large language models basics and usage\n",
    "\n",
    "**Big goal:** learn machine learning basics through applications. (Theory is awesome, but most of us just want to passs a interview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ff1f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "View course website and show the following: \n",
    "- Course staff\n",
    "- Course structure\n",
    "- Homeworks\n",
    "- Exams\n",
    "- Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a2b0a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lecture plan:\n",
    "\n",
    "- Introduction to PyTorch \n",
    "- Sample PyTorch Code \n",
    "- Tensor Basics\n",
    "- Tensor Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe10ccb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1:  Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157bb8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is PyTorch? \n",
    "\n",
    "PyTorch is a open-source machine learning library used for various tasks that require some level of model optimization like natural language processing, computer vision. \n",
    "\n",
    "- Originally developed by Meta AI and now a part of the Linux Foundation \n",
    "- Developed in conjunction with with Convolutional Architecture for Fast Feature Encoding (Caffe2) (C++  machine learning framework) \n",
    "    - But models between frameworks were incompatible ...\n",
    "    - So Meta and Microsoft created the Open Neural Network Exchange (ONNX) for converting ML models between frameworks\n",
    "    - Caffe2 was merged into PyTorch 2 years later \n",
    "- PyTorch 2 was released in 2023 and introduced TorchDynamo, a Python level compiler that offered a lot of ML specific optimizations and significant speed-ups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269be55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why use PyTorch\n",
    "\n",
    "When PyTorch was introduced in 2017, Tensorflow and Keras (Tersorflow wrapper) were already mature machine learning libraries. But now 85% of academic papers use PyTorch: **why?**\n",
    "\n",
    "- Simplicity - easy to use, **extend** and debug\n",
    "- Python integration - Python is now the most popular language in the world\n",
    "- The tensor data type, perfect abstraction of NumPy data\n",
    "- Accelerated computation using GPUs\n",
    "- Early Caffe2 integration gave it a high performing C++ compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69472e33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Feeling out PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde356e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Software installation and initialization\n",
    "\n",
    "[Install PyTorch using anaconda or pip](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "Check your successful installation using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8173cdfa",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3ff9a6",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadb276",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Datasets\n",
    "\n",
    "Many classic datasets come [preprogrammed into PyTorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Let's look at one of these datasets: [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "*Due to licensing issues CIFAR is no longer a default in the PyTorch library but it is still easily accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e740e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#credit to https://jamesmccaffrey.wordpress.com/2020/08/07/displaying-cifar-10-images-using-pytorch/\n",
    "\n",
    "import torch as T\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5   # unnormalize\n",
    "  npimg = img.numpy()   # convert from tensor\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(),\n",
    "transforms.Normalize((0.5, 0.5, 0.5),\n",
    "  (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = tv.datasets.CIFAR10(root='.\\\\data', train=True, download=True, transform=transform)\n",
    "trainloader = T.utils.data.DataLoader(trainset,\n",
    "batch_size=100, shuffle=False, num_workers=1)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog',\n",
    "#   'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# get first 100 training images\n",
    "dataiter = iter(trainloader)\n",
    "imgs, lbls = next(dataiter)\n",
    "\n",
    "images = []\n",
    "for i in range(100):  # show just the cars\n",
    "    if lbls[i] == 1:  # 1 = car\n",
    "        images.append(imgs[i])\n",
    "\n",
    "images_grid = tv.utils.make_grid(images, nrow=10)        \n",
    "imshow(images_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c3730",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Small Torch Model\n",
    "\n",
    "[AlexNet](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf): \n",
    "\n",
    "<img align=\"left\" src=\"img/alexnet.jpg\" width=\"1000px\" style=\"padding:30px;border:thin solid white;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0a633",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebook demonstration (on Google colab)\n",
    "\n",
    "- http://colab.research.google.com (provides access to GPUs and TPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdf7ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 3: Introduction to Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89418742",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's think about vectors and how we would initialize/use them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d549e03e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "vec1 = [1,2,3]\n",
    "\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8ecd93f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vec2 = np.array(vec1)\n",
    "print(vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d046e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why do we use numpy if vanilla python has arrays/matrices anyway? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebf5d15a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "size_of_vec = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f902da58",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Python time: 0.235685\n"
     ]
    }
   ],
   "source": [
    "def pure_python_version():\n",
    "    t1 = time.time()\n",
    "    X = range(size_of_vec)\n",
    "    Y = range(size_of_vec)\n",
    "    Z = [X[i] + Y[i] for i in range(len(X)) ]\n",
    "    return time.time() - t1\n",
    "\n",
    "t1 = pure_python_version()\n",
    "print('Pure Python time: {:.6f}'.format(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd4352e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy time: 0.018518\n"
     ]
    }
   ],
   "source": [
    "def numpy_version():\n",
    "    t1 = time.time()\n",
    "    X = np.arange(size_of_vec)\n",
    "    Y = np.arange(size_of_vec)\n",
    "    Z = X + Y\n",
    "    return time.time() - t1\n",
    "\n",
    "t2 = numpy_version()\n",
    "print('Numpy time: {:.6f}'.format(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d21a4c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why does NumPy perform so much faster than normal Python arrays (Hint, isn't the lack of commas weird)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a6a83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What about tensors? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94add72c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Vectors are 1-D arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1c6ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Matrices are 2-D arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c839faf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Tensors are n-dimensional arrays of various sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd3227",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to create a Torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b48c3f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2], [3, 4, 5]]\n"
     ]
    }
   ],
   "source": [
    "a = [[j+3*i for j in range(3)] for i in range(2)]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb2ba27",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(a)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0e250c3",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "#Initialize from normal python array\n",
    "\n",
    "import torch\n",
    "a_data = torch.tensor(a)\n",
    "print(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a236309f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "#Initialize from NumPy array\n",
    "\n",
    "\n",
    "a_np = torch.from_numpy(np_array)\n",
    "print(a_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385891a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful tensor initializations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0c04871",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[[0.5547, 0.3423, 0.6343, 0.3644],\n",
      "         [0.7104, 0.9464, 0.7890, 0.2814],\n",
      "         [0.7886, 0.5895, 0.7539, 0.1952]],\n",
      "\n",
      "        [[0.0050, 0.3068, 0.1165, 0.9103],\n",
      "         [0.6440, 0.7071, 0.6581, 0.4913],\n",
      "         [0.8913, 0.1447, 0.5315, 0.1587]]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[[1, 1, 1, 1],\n",
      "         [1, 1, 1, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1],\n",
      "         [1, 1, 1, 1],\n",
      "         [1, 1, 1, 1]]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,4)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape, dtype=int)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(\"Random Tensor: \\n {} \\n\".format(rand_tensor))\n",
    "print(\"Ones Tensor: \\n {} \\n\".format(ones_tensor))\n",
    "print(\"Zeros Tensor: \\n {}\".format(zeros_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6d22f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some simple Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e63e539",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(\"Shape of tensor: {}\".format(tensor.shape))\n",
    "print(\"Datatype of tensor: {}\".format(tensor.dtype))\n",
    "print(\"Device tensor is stored on: {}\".format(tensor.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c16a40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tensor indexing\n",
    "\n",
    "Tensors can be indexed just like NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "111ba0d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "a = [[j+3*i for j in range(3)] for i in range(2)]\n",
    "a_tensor = torch.tensor(a)\n",
    "print(a_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f122d57b",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# example of slicing\n",
    "print(a_tensor[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf3f40c5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(a_tensor[1,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6efe3802",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[42, 67, 76, 14],\n",
      "         [26, 35, 20, 24],\n",
      "         [50, 13, 78, 14]],\n",
      "\n",
      "        [[10, 54, 31, 72],\n",
      "         [15, 95, 67,  6],\n",
      "         [49, 76, 73, 11]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Generate random integers\n",
    "aa = torch.randint(0, 100, (2, 3, 4))\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d018fa51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[42, 67, 76, 14],\n",
      "         [26, 35, 20, 24],\n",
      "         [50, 13, 78, 14]],\n",
      "\n",
      "        [[10, 54, 31, 72],\n",
      "         [15, 95, 67,  6],\n",
      "         [49, 76, 73, 11]]])\n"
     ]
    }
   ],
   "source": [
    "print(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca42ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alertness Check - **What is the index of the value \"78\" ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29d3f50b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor(78)\n"
     ]
    }
   ],
   "source": [
    "print(aa.shape)\n",
    "print(aa[0][2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ffcb870",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(aa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ebcfe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Tensor Operations\n",
    "\n",
    "Same idea as with NumPy arrays/matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb03c38",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0, 2, 4],\n",
      "        [1, 3, 5]])\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "a = [[i+3*j for i in range(3)] for j in range(2)]\n",
    "b = [[j+2*i for i in range(3)] for j in range(2)]\n",
    "c = [[int(i+3*j%2==1) for i in range(2)] for j in range(3)]\n",
    "\n",
    "a_tensor = torch.tensor(a)\n",
    "b_tensor = torch.tensor(b)\n",
    "c_tensor = torch.tensor(c)\n",
    "print(a_tensor)\n",
    "print(b_tensor)\n",
    "print(c_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56ed9061",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_tensor.mul(b_tensor) \n",
      " tensor([[ 0,  2,  8],\n",
      "        [ 3, 12, 25]]) \n",
      "\n",
      "a_tensor * b_tensor \n",
      " tensor([[ 0,  2,  8],\n",
      "        [ 3, 12, 25]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the ****** product\n",
    "print(f\"a_tensor.mul(b_tensor) \\n {a_tensor.mul(b_tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"a_tensor * b_tensor \\n {a_tensor * b_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfb5b94e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[1.0899, 1.0192, 0.7508],\n",
      "        [1.0192, 1.9040, 0.8580],\n",
      "        [0.7508, 0.8580, 0.6950]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[1.0899, 1.0192, 0.7508],\n",
      "        [1.0192, 1.9040, 0.8580],\n",
      "        [0.7508, 0.8580, 0.6950]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c907d98-20f5-460d-808b-fd51893c2838",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      "\n",
      "Transposed tensor \n",
      " tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]]) \n",
      "\n",
      "Another way to transpose the tensor \n",
      " tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This transposes a tensor\n",
    "print('Original tensor \\n {} \\n'.format(a_tensor))\n",
    "print('Transposed tensor \\n {} \\n'.format(a_tensor.T))\n",
    "print('Another way to transpose the tensor \\n {} \\n'.format(torch.transpose(a_tensor, dim0=0, dim1=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b64dea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alertness check: **Why is there a a dim0/dim1 option in tensor.transpose?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efb33e16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "Original Vector:\n",
      "tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1],\n",
      "         [1, 1, 1, 1],\n",
      "         [1, 1, 1, 1]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[i for k in range(4)] for j in range(3)] for i in range(2)])\n",
    "print(x.shape)\n",
    "print(\"Original Vector:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479cd4d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's say we want to change x to be a $4\\times 3 \\times 2$ tensor? How to we transpose it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59a992a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Vector:\n",
      "tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1],\n",
      "         [1, 1, 1, 1],\n",
      "         [1, 1, 1, 1]]])\n",
      "torch.Size([2, 3, 4])\n",
      "None\n",
      "Transposed Vector (Dim = ?):\n",
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]]])\n",
      "torch.Size([4, 3, 2])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Vector:\")\n",
    "print(x)\n",
    "print(print(x.shape))\n",
    "print(\"Transposed Vector (Dim = ?):\")\n",
    "xt=torch.transpose(x, dim0=2, dim1=0)\n",
    "print(xt)\n",
    "print(print(xt.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1f1d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img align=\"left\" src=\"img/transpose_example_2.png\" width=\"600px\" style=\"padding:30px;border:thin solid white;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c5194",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we do x.T?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "193bf746",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30726068",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Why?](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609727f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Elementwise operations\n",
    "\n",
    "Many functions can be applied on a tensor element by element\n",
    "- torch.cos\n",
    "- torch.sin\n",
    "- torch.exp\n",
    "- torch.log\n",
    "\n",
    "These functions **return a new tensor** with the function being applied to each element in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b897610b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones([4,4])\n",
    "b = torch.log(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf074a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In-place operations\n",
    "\n",
    "Operations that have a ```_``` suffix are in-place. For example: ```x.copy_(y)```, ```x.t_()```, ```x.exp_()```, will change ```x```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "790e73f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57260431",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interaction with NumPy\n",
    "\n",
    "You'll likely need to convert between a NumPy array (usually when plotting data/results). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5f31e7c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert from tensor to NumPy array\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "print(tensor)\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "386dd8a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Covert from NumPy array to torch:\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef481758",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cool thing is that changes in NumPy array are reflected in the tensor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4cfb50bb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c90264",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Both numpy array and tensor data point to the same contiguous block in memory. Very different than view, speaking of which: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321f9ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensor Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bb47e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Imagine we want to access part of a tensor (e.g., first row) or we want to permute rows and columns. Do we really need to allocate new memory to store this part of the tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718056b7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "No:\n",
    "- a tensor can be a \"view\" of an existing tensor\n",
    "- a \"view\" of a tensor shares the data with the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7c441f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[4*i+j for j in range(4)] for i in range(4)])\n",
    "b = a.view(2, 8)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d327be62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   2,   3],\n",
      "        [100, 100, 100, 100],\n",
      "        [  8,   9,  10,  11],\n",
      "        [ 12,  13,  14,  15]])\n",
      "tensor([[  0,   1,   2,   3, 100, 100, 100, 100],\n",
      "        [  8,   9,  10,  11,  12,  13,  14,  15]])\n"
     ]
    }
   ],
   "source": [
    "a[1] = 100\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053f17f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How much memory does ```a``` and ```b``` consume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41188324",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is sized: 88\n",
      "b is sized: 88\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"a is sized: \" + str(sys.getsizeof(a)))\n",
    "print(\"b is sized: \" + str(sys.getsizeof(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60ffe4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Makes sense right? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "16ddc5d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c is sized: 88\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([[4*i+j for j in range(100)] for i in range(100)])\n",
    "print(\"c is sized: \" + str(sys.getsizeof(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00364f3e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Wait what? Why is every sized the same?! c is so much bigger....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59ce302e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data in 'a' is sized: 128\n",
      "The data in 'b' is sized: 128\n",
      "The data in 'c' is sized: 80000\n"
     ]
    }
   ],
   "source": [
    "print(\"The data in 'a' is sized: \" + str(a.element_size() * a.nelement()))\n",
    "print(\"The data in 'b' is sized: \" + str(b.element_size() * b.nelement()))\n",
    "print(\"The data in 'c' is sized: \" + str(c.element_size() * c.nelement()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "668d0b39",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do 'a' and 'b' share a view? True\n",
      "Do 'a' and 'c' share a view? False\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[4*i+j for j in range(4)] for i in range(4)])\n",
    "b = a.view(-1, 16)\n",
    "c = torch.tensor([[5*i+j for j in range(5)] for i in range(5)])\n",
    "\n",
    "def same_storage(x, y):\n",
    "    return x.storage().data_ptr() == y.storage().data_ptr()\n",
    "\n",
    "print(\"Do 'a' and 'b' share a view? \" + str(same_storage(a, b)))\n",
    "print(\"Do 'a' and 'c' share a view? \" + str(same_storage(a, c))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f852f0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hard to know what creates a view and what creates a copy, but general rule of thumb is that a view is created unless there are no other options: \n",
    "\n",
    "|Creates tensor views| Creates tensor copies|\n",
    "|:-------------------|:------------------|\n",
    "|  ```view()``` - reshapes tensor     |   ```clone()``` - explicity creates a copy|\n",
    "|  ```narrow()``` - extracts contiguous subset of tensor     |   ```detach()``` - creates a new tesnor detached from computational graph|\n",
    "| ```transpose()``` - swaps two dimensions of a tensor | ```copy() ``` - copies data from one tensor to another|\n",
    "| ```permute()``` - generalizes transpose to many dimensions | ```to() ``` - copies data to gpu|\n",
    "| ```squeeze()``` - removes dimensions of size 1 | |\n",
    "| ```unsqueeze()``` - add dimension of size 1 | |\n",
    "| ```as_strided()``` - creates a view with non-contiguous strides (advanced) | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ed390",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tensor strides\n",
    "\n",
    "How do we create a new tensor with different dimensions, but with the same data? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411219dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b04a5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Imagine that this is a tensor: \n",
    "\n",
    "<img align=\"left\" src=\"img/stride_tensor_example.png\" width=\"300px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n",
    "The tensor class hold many properties: \n",
    "\n",
    "- sizes: (w,h,d)\n",
    "- dtype: int/float/...\n",
    "- device: cpu/gpu\n",
    "- layout: strided\n",
    "- strides: (w*h, w, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16ced9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Strided representation: \n",
    "\n",
    "<img align=\"left\" src=\"img/stride_mapping_example.png\" width=\"450px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n",
    "So for instance, the element at index [1,0] corresponds to the memory at: base_ptr + (1*stride[0] + 0*stride[1])*size(dtype)\n",
    "\n",
    "For the left example it would be: 0x10+(1*2+0*1)*4=0x18\n",
    "\n",
    "*credit to: http://blog.ezyang.com/2019/05/pytorch-internals/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb04c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining Tensors\n",
    "\n",
    "We can concatenate tensors along different dimensions **that already exist**! All other dimensions must match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ecff214",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.cat((a,a,a),dim=0)\n",
    "c = torch.cat((a,a,a),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47ad71de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n",
      "\n",
      "Concatenate in dimension 0 (rows)\n",
      "torch.Size([6, 3])\n",
      "tensor([[ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n",
      "\n",
      "Concatenate in dimension 1 (rows)\n",
      "torch.Size([2, 9])\n",
      "tensor([[ 1.1103, -1.6898, -0.9890,  1.1103, -1.6898, -0.9890,  1.1103, -1.6898,\n",
      "         -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172,  0.9580,  1.3221,  0.8172,  0.9580,  1.3221,\n",
      "          0.8172]])\n"
     ]
    }
   ],
   "source": [
    "print('Original tensor')\n",
    "print(a.shape)\n",
    "print(a)\n",
    "print('')\n",
    "print('Concatenate in dimension 0 (rows)')\n",
    "print(b.shape)\n",
    "print(b)\n",
    "print('')\n",
    "print('Concatenate in dimension 1 (rows)')\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddd1d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alertness check: Do ```a``` and ```b``` share the same storage? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d126df47",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(same_storage(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfcd503-ce9c-4f45-a6f0-16b851943ab2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also stack tensors along a **new dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099998e-9be3-4845-83fe-04346d871d80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.stack((a,a,a,a),dim=0)\n",
    "c = torch.stack((a,a,a,a),dim=1)\n",
    "d = torch.stack((a,a,a,a),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66313b79-3d42-4459-988b-881f638643c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n",
      "\n",
      "Stack in dimension 0\n",
      "torch.Size([6, 3])\n",
      "tensor([[ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n",
      "\n",
      "Stack in dimension 1\n",
      "torch.Size([100, 100])\n",
      "tensor([[  0,   1,   2,  ...,  97,  98,  99],\n",
      "        [  4,   5,   6,  ..., 101, 102, 103],\n",
      "        [  8,   9,  10,  ..., 105, 106, 107],\n",
      "        ...,\n",
      "        [388, 389, 390,  ..., 485, 486, 487],\n",
      "        [392, 393, 394,  ..., 489, 490, 491],\n",
      "        [396, 397, 398,  ..., 493, 494, 495]])\n",
      "Stack in dimension 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStack in dimension 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(d\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(d)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "print('Original tensor')\n",
    "print(a.shape)\n",
    "print(a)\n",
    "print('')\n",
    "print('Stack in dimension 0')\n",
    "print(b.shape)\n",
    "print(b)\n",
    "print('')\n",
    "print('Stack in dimension 1')\n",
    "print(c.shape)\n",
    "print(c)\n",
    "print('Stack in dimension 2')\n",
    "print(d.shape)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7993b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adding dimensions\n",
    "\n",
    "We can also add dimensions if we need them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "401a219a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = a.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "89ec3463",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(b.shape)\n",
    "c = b.squeeze(0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d512e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Converting from one datatype to another\n",
    "\n",
    "Use the ```Tensor.to(...)``` function but keep in mind possible loss of bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2729bf3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2,4), dtype=torch.int32)\n",
    "print(x)\n",
    "y = x.to(torch.float64)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf501bab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can do this to save space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e297071",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## That is it for now\n",
    "\n",
    "### Will discuss storage, indexing, data-types, and functions next time!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
