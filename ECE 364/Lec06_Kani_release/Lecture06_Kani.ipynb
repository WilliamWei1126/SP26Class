{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img align=\"left\" src=\"img/ECE364-logo.png\" width=\"300px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n",
    "# Lecture 6 - Primal optimization\n",
    "## ECE364 - Programming Methods for Machine Learning\n",
    "### Nickvash Kani \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Slides based off prior lectures by Alex Schwing, Aigou Han, Farzas Kamalabadi, Corey Snyder. All mistakes are my own!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this lecture we will cover: \n",
    "\n",
    "- Basics of optimization\n",
    "- Convexity\n",
    "- Steepest descent\n",
    "- Gradient momentum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's primal optimization? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**1. Primal Optimization Problem**\n",
    "- The **primal problem** is the original optimization problem we want to solve.\n",
    "- Typically, it is formulated as a **minimization** or **maximization** problem with constraints.\n",
    "- It involves decision variables, an objective function, and constraints.\n",
    "\n",
    "**Example of a Primal Problem (Convex Optimization Form)**\n",
    "$$\n",
    "\\min_{x} \\quad f(x)\n",
    "$$\n",
    "$$\n",
    "\\text{subject to } g_i(x) \\leq 0, \\quad i = 1, ..., m\n",
    "$$\n",
    "$$\n",
    "h_j(x) = 0, \\quad j = 1, ..., p\n",
    "$$\n",
    "where:\n",
    "- \\( f(x) \\) is the objective function.\n",
    "- \\( g_i(x) \\) are inequality constraints.\n",
    "- \\( h_j(x) \\) are equality constraints.\n",
    "- \\( x \\) are the primal decision variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2. Dual Optimization Problem**\n",
    "- The **dual problem** is derived from the primal problem using Lagrange multipliers.\n",
    "- Instead of optimizing over the original decision variables $x$, it optimizes over the Lagrange multipliers.\n",
    "- The dual problem provides a **lower bound** (in minimization problems) or an **upper bound** (in maximization problems) to the primal solution.\n",
    "- **Strong duality** holds under certain conditions (e.g., Slater’s condition in convex problems), meaning the primal and dual solutions are equal.\n",
    "\n",
    "### **Forming the Dual Problem**\n",
    "We construct the **Lagrangian function**:\n",
    "$$\n",
    "L(x, \\lambda, \\nu) = f(x) + \\sum_{i=1}^{m} \\lambda_i g_i(x) + \\sum_{j=1}^{p} \\nu_j h_j(x)\n",
    "$$\n",
    "where:\n",
    "- $\\lambda_i \\geq 0$ are **dual variables (Lagrange multipliers)** for inequality constraints.\n",
    "- $\\nu_j$ are **dual variables** for equality constraints.\n",
    "\n",
    "The **dual function** is:\n",
    "$$\n",
    "\\theta(\\lambda, \\nu) = \\inf_x L(x, \\lambda, \\nu)\n",
    "$$\n",
    "Then, the **dual optimization problem** is:\n",
    "$$\n",
    "\\max_{\\lambda \\geq 0, \\nu} \\theta(\\lambda, \\nu)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**We don't need to know about dual optimization in this course**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Returning back to our optimization problem\n",
    "\n",
    "The problem more generally: \n",
    "$$\n",
    "\\min_{x} \\quad f(x)\n",
    "$$\n",
    "$$\n",
    "\\text{subject to } g_i(x) \\leq 0, \\quad i = 1, ..., m\n",
    "$$\n",
    "\n",
    "**Solution:**\n",
    "Solution $x^*$ has smallest value $f_0(w^*)$ amon gall the values that satisfythe constraints.\n",
    "\n",
    "<img align=\"center\" src=\"img/minima.png\" width=\"600px\" style=\"padding:30px;border:thin solid white;\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Questions: \n",
    "\n",
    "- When can we find the optima? \n",
    "- What algorithms are there to find the optima? \n",
    "- How long does it take to find the optima?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convexity\n",
    "\n",
    "**Understanding the Convexity Inequality**\n",
    "\n",
    "A **convex function** is a function where the line segment between any two points on its graph lies **above or on the graph** of the function. This property ensures that the function does not have \"dips\" or \"valleys\" beyond what is expected from a convex shape.\n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"img/convex.png\" width=\"500px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Mathematical Definition**\n",
    "\n",
    "A function $ f: \\mathbb{R}^n \\to \\mathbb{R} $ is **convex** if, for all points $ x, y \\in \\mathbb{R}^n $ and for all $ \\lambda \\in [0,1] $, the following inequality holds:\n",
    "\n",
    "$$\n",
    "f(\\lambda x + (1-\\lambda) y) \\leq \\lambda f(x) + (1-\\lambda) f(y)\n",
    "$$\n",
    "\n",
    "This condition means that for any two points $ x $ and $ y $, the function evaluated at any convex combination of these points is **less than or equal to** the corresponding convex combination of function values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Examples of Convex Functions**\n",
    "\n",
    "- **Exponential**: $ \\exp(a x) $ is convex on $ x \\in \\mathbb{R} $ for all $ a \\in \\mathbb{R} $.\n",
    "- **Negative Logarithm**: $ -\\log(x) $ is convex on $ x \\in \\mathbb{R}_{++} $.\n",
    "- **Negative Entropy**: $ -H(x) = x \\log(x) $ is convex on $ x \\in \\mathbb{R}_{++} $.\n",
    "- **Norms**: $ \\| w \\|_p $ for $ p \\geq 1 $.\n",
    "- **Log-Sum-Exp**: $ \\log(\\exp(w_1) + \\dots + \\exp(w_d)) $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Operations Which Preserve Convexity**\n",
    "\n",
    "- **Non-negative weighted sums**: $ \\alpha_i \\geq 0 $; if $ f_i $ are convex for all $ i $, then so is:\n",
    "\n",
    "  $$\n",
    "  g = \\alpha_1 f_1 + \\alpha_2 f_2 + \\dots\n",
    "  $$\n",
    "\n",
    "- **Composition with an affine mapping**: If $ f $ is convex, then so is:\n",
    "\n",
    "  $$\n",
    "  g(\\mathbf{w}) = f(A\\mathbf{w} + b)\n",
    "  $$\n",
    "\n",
    "- **Pointwise maximum**: If $ f_1, f_2 $ are convex, then so is:\n",
    "\n",
    "  $$\n",
    "  g(\\mathbf{w}) = \\max \\{ f_1(\\mathbf{w}), f_2(\\mathbf{w}) \\}\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Why is convexity important?**\n",
    "\n",
    "- **Global Optimality Guarantee** If a function **is convex**, any **local minimum is also a global minimum**. This is a crucial property because, in general, non-convex functions may have multiple local minima, making it difficult to find the best solution. Formally, for a convex function $ f(x) $, if $ x^* $ satisfies:\n",
    "\n",
    "  $$\n",
    "  \\nabla f(x^*) = 0\n",
    "  $$\n",
    "\n",
    "  then $ x^* $ is a **global minimum**.\n",
    "\n",
    "\n",
    "\n",
    "- **Efficient Algorithms for Convex Problems** Convex optimization problems can often be solved **efficiently** using well-established algorithms, including:\n",
    "    - **Gradient Descent** (for smooth convex functions)\n",
    "    - **Newton’s Method** (for strongly convex functions)\n",
    "    - **Interior-Point Methods** (for constrained convex optimization)\n",
    "    - **Simplex and Interior-Point Methods** (for convex Linear Programming problems)\n",
    "\n",
    "    These algorithms are guaranteed to converge to the global minimum under appropriate conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we find the minima? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Iterative Algorithm**\n",
    "\n",
    "- **Start with some guess** $ \\mathbf{w} $\n",
    "- **Iterate** $ k = 1, 2, 3, \\dots $\n",
    "  - Select direction $ d_k $ and step size $ \\alpha_k $\n",
    "  - Update:  \n",
    "    $$\n",
    "    \\mathbf{w} \\gets \\mathbf{w} + \\alpha_k d_k\n",
    "    $$\n",
    "  - Check whether we should stop (e.g., if $ \\nabla f(\\mathbf{w}) \\approx 0 $)\n",
    "\n",
    "---\n",
    "\n",
    "**Descent Direction**\n",
    "\n",
    "The descent direction $ d_k $ satisfies:\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{w})^\\top d_k < 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**How to select direction $d_k$**\n",
    "\n",
    "- Steepest Descent: $d_k = -\\nabla f(w_k)$ \n",
    "\n",
    "<img align=\"center\" src=\"img/descent.png\" width=\"400px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Other directions also used: \n",
    "\n",
    "- **Scaled gradient** $d_k = -D_k \\nabla f(w_k)$ where $D_k$ is a scaling matrix (also called preconditioner)\n",
    "- etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**How to Select Stepsize**\n",
    "\n",
    "- **Exact**:  \n",
    "  $$ \\alpha_k = \\arg \\min_{\\alpha \\geq 0} f(\\mathbf{w}_k + \\alpha d_k) $$\n",
    "\n",
    "- **Constant**:  \n",
    "  $$ \\alpha_k = \\mathbb{R} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Steepest descent + constant step size is gradient descent!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So what's the problem? Can we call the lecture over? [Interactive web tool](https://fa.bianp.net/teaching/2018/COMP-652/gradient_descent.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**How to Select Stepsize (continued)**\n",
    "\n",
    "**Optimal line search** At every iteration $k$, **optimal line search** computes the step size $ \\varepsilon_k $ as follows:\n",
    "\n",
    "$$\n",
    "\\varepsilon_k = \\arg \\min_{\\varepsilon \\geq 0} f(\\mathbf{x}_k + \\varepsilon d_k). \\tag{3.3}\n",
    "$$\n",
    "\n",
    "Clearly, the above problem presumes a chosen **direction of motion** $ d_k $. The method searches for the value of $ \\varepsilon_k $ over the half-line $ [0, \\infty) $, therefore it is called **optimal line search**. \n",
    "\n",
    "By this description, it is clear that **optimal line search** corresponds to a sequence of **optimal local decisions**, yielding maximum reduction of $ f $ at every iteration $ k $, given that the current state or position is $ \\mathbf{x}_k $ and the descent direction has been chosen to be $ d_k $.\n",
    "\n",
    "Solving for $ \\varepsilon $ at every iteration of the **gradient or steepest descent algorithms** may be **difficult and costly**.\n",
    "\n",
    "This motivates the **Armijo rule**. [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Armijo’s Rule in Machine Learning**\n",
    "\n",
    "**Armijo’s rule** is a step size selection method used in **gradient-based optimization** to ensure sufficient **decrease in the objective function** while maintaining stability. It is widely used in **line search methods** for optimization, particularly in **gradient descent, Newton’s method, and quasi-Newton methods**.\n",
    "\n",
    "---\n",
    "\n",
    "**Armijo’s Rule for Step Size Selection**\n",
    "Armijo’s rule uses a **backtracking approach** to find a suitable step size $ \\alpha $:\n",
    "\n",
    "1. **Start** with an initial step size $ \\alpha = s $.\n",
    "2. **Check** if the Armijo condition holds:\n",
    "\n",
    "   $$\n",
    "   f(\\mathbf{w}_k + \\alpha d_k) - f(\\mathbf{w}_k) \\leq \\sigma \\alpha \\nabla f(\\mathbf{w}_k)^T d_k\n",
    "   $$\n",
    "\n",
    "3. If the condition **does not hold**, reduce $ \\alpha $ using a decay factor $ \\beta $:\n",
    "\n",
    "   $$\n",
    "   \\alpha = \\beta \\alpha, \\quad \\text{(e.g., with } \\beta = 0.5)\n",
    "   $$\n",
    "\n",
    "4. **Repeat** until a suitable $ \\alpha $ is found.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Armijo’s Condition**\n",
    "The **Armijo condition** ensures that the function value decreases sufficiently after taking a step in the descent direction. Given an objective function $ f(\\mathbf{w}) $, the step size $ \\alpha $ must satisfy:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{w}_k + \\alpha d_k) - f(\\mathbf{w}_k) \\leq \\sigma \\alpha \\nabla f(\\mathbf{w}_k)^T d_k\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{w}_k $ is the current iterate.\n",
    "- $ d_k $ is the descent direction (e.g., $ d_k = -\\nabla f(\\mathbf{w}_k) $ in gradient descent).\n",
    "- $ \\alpha $ is the step size.\n",
    "- $ \\sigma \\in (0,1) $ is a parameter that controls how much decrease is required (typically, $ \\sigma \\approx 0.1 $).\n",
    "\n",
    "This condition ensures that:\n",
    "\n",
    "- **Ensures sufficient decrease**: The left-hand side, $ f(\\mathbf{w}_k + \\alpha d_k) - f(\\mathbf{w}_k) $, represents the actual change in the function value after taking a step.\n",
    "- **Bounds the decrease**: The right-hand side, $ \\sigma \\alpha \\nabla f(\\mathbf{w}_k)^T d_k $, represents a fraction of the expected decrease based on the **first-order Taylor approximation**:\n",
    "\n",
    "  $$\n",
    "  f(\\mathbf{w}_k + \\alpha d_k) \\approx f(\\mathbf{w}_k) + \\alpha \\nabla f(\\mathbf{w}_k)^T d_k\n",
    "  $$\n",
    "\n",
    "  The condition ensures that the actual decrease is **at least a fraction \\( \\sigma \\) of the predicted decrease**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using a smart step size helps stabalize gradient descent (and make things faster too!) [Interactive web tool](https://fa.bianp.net/teaching/2018/COMP-652/gradient_descent.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Momentum in gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One problem with gradient descent is that it has no memory. \n",
    "- If the gradient is pointing left, it'll go left. \n",
    "- Next iteration if the gradient is pointing right, it goes right. \n",
    "- This issue is especially bad for cases where the gradients are uneven among dimensions:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img align=\"center\" src=\"img/gradient_descent_principle_component.png\" width=\"800px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n",
    "The ratio between the length of the longest and shortest principle axes of this ellipse is known as the condition number: \n",
    "\n",
    "$$\\kappa = \\left(\\frac{a}{b}\\right)^2$$\n",
    "\n",
    "In order to get within $\\epsilon$ of a minima, we need $\\geq \\kappa \\log\\left(\\frac{1}{\\epsilon}\\right)$ iterations [Gradient Descent Condition Number Dependence](https://en.wikipedia.org/wiki/Condition_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the loss function f(x1, x2) = (x1 - 20)^2 / 20 + 2 * x2^2\n",
    "def loss_function(x):\n",
    "    return (x[0] - 20) ** 2 / 20 + 2 * x[1] ** 2\n",
    "\n",
    "# Gradient of the loss function\n",
    "def compute_gradient(x):\n",
    "    grad_x1 = 2 * (x[0] - 20) / 20\n",
    "    grad_x2 = 2 * 2 * x[1]\n",
    "    return torch.tensor([grad_x1, grad_x2])\n",
    "\n",
    "# Optimization settings\n",
    "learning_rate = 0.48\n",
    "iterations = 50\n",
    "\n",
    "# Initial point\n",
    "x_gd = torch.tensor([-5.0, -5.0])\n",
    "\n",
    "# Store trajectory for plotting\n",
    "gd_trajectory = [x_gd.numpy()]\n",
    "\n",
    "# Perform optimization\n",
    "for _ in range(iterations):\n",
    "    grad_gd = compute_gradient(x_gd)\n",
    "    x_gd = x_gd - learning_rate * grad_gd\n",
    "    gd_trajectory.append(x_gd.numpy())\n",
    "\n",
    "# Convert trajectory to NumPy for plotting\n",
    "gd_trajectory = np.array(gd_trajectory)\n",
    "\n",
    "# Create meshgrid for contour plot\n",
    "x1_vals = np.linspace(-10, 40, 100)\n",
    "x2_vals = np.linspace(-10, 10, 100)\n",
    "X1, X2 = np.meshgrid(x1_vals, x2_vals)\n",
    "Z = loss_function([X1, X2])\n",
    "\n",
    "# Create figure and contour plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "contour = ax.contour(X1, X2, Z, levels=30, cmap='viridis')\n",
    "ax.clabel(contour, inline=True, fontsize=8)\n",
    "\n",
    "# Plot Gradient Descent trajectory\n",
    "ax.plot(gd_trajectory[:, 0], gd_trajectory[:, 1], 'r-o', markersize=4, label=\"Gradient Descent\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_title('Gradient Descent Optimization Path')\n",
    "#ax.legend()\n",
    "\n",
    "# Save the plot as an image file\n",
    "image_filename = \"./img/gradient_descent.png\"\n",
    "plt.savefig(image_filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "**Gradient Descent with Momentum** is an optimization algorithm that improves standard **gradient descent** by **accelerating convergence** and **reducing oscillations**, especially in highly curved loss landscapes.\n",
    "\n",
    "---\n",
    "\n",
    "**Update Rule for Gradient Descent with Momentum**\n",
    "In standard gradient descent, the update rule is:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{k+1} = \\mathbf{w}_k - \\alpha \\nabla f(\\mathbf{w}_k)\n",
    "$$\n",
    "\n",
    "In **gradient descent with momentum**, we introduce a **velocity term** \\( v_k \\):\n",
    "\n",
    "1. **Compute the velocity (momentum update)**:\n",
    "   $$\n",
    "   v_{k+1} = \\beta v_k - \\alpha \\nabla f(\\mathbf{w}_k)\n",
    "   $$\n",
    "\n",
    "2. **Update weights using velocity**:\n",
    "   $$\n",
    "   \\mathbf{w}_{k+1} = \\mathbf{w}_k + v_{k+1}\n",
    "   $$\n",
    "\n",
    "where:\n",
    "- $ \\alpha $ is the **learning rate**.\n",
    "- $ \\beta \\in [0,1] $ is the **momentum coefficient**, typically **0.9**.\n",
    "- $ v_k $ is the **velocity term** (tracks accumulated gradients).\n",
    "\n",
    "---\n",
    "\n",
    "**Intuition Behind Momentum**\n",
    "- Think of **momentum as a ball rolling down a hill**: it builds speed in a direction and resists small changes.\n",
    "- Instead of **just using the current gradient**, it **accumulates past gradients** to make updates smoother and faster.\n",
    "\n",
    "---\n",
    "\n",
    "**Momentum Helps By:**\n",
    "- Accumulating **past gradients** to **smooth updates**.\n",
    "- **Accelerating convergence** by moving in a consistent direction.\n",
    "- **Reducing oscillations** by dampening fluctuations in gradient updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient descent with and without momentum ($\\alpha=0.2$)\n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"img/gradient_vs_momentum_alpha_0_2.gif\" width=\"900px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### Gradient descent with and without momentum ($\\alpha=0.5$)\n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"img/gradient_vs_momentum_alpha_0_5.gif\" width=\"900px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define the loss function f(x1, x2) = (x1 - 10)^2 / 20 + x2^2\n",
    "def loss_function(x):\n",
    "    return (x[0] - 20) ** 2 / 20 + 2 * x[1] ** 2\n",
    "\n",
    "# Gradient of the loss function\n",
    "def compute_gradient(x):\n",
    "    grad_x1 = 2 * (x[0] - 20) / 20\n",
    "    grad_x2 = 2 * 2 * x[1] ** 1\n",
    "    return torch.tensor([grad_x1, grad_x2])\n",
    "\n",
    "# Optimization settings\n",
    "learning_rate = 0.2\n",
    "momentum = 0.9\n",
    "iterations = 50\n",
    "\n",
    "# Initial point (starting from a far-off place)\n",
    "x_gd = torch.tensor([-5.0, -5.0])\n",
    "x_gdm = torch.tensor([-5.0, -5.0])\n",
    "\n",
    "# Lists to store trajectory for plotting\n",
    "gd_trajectory = [x_gd.detach().numpy()]\n",
    "gdm_trajectory = [x_gdm.detach().numpy()]\n",
    "\n",
    "# Momentum velocity term\n",
    "velocity = torch.tensor([0.0, 0.0])\n",
    "\n",
    "# Perform optimization\n",
    "for _ in range(iterations):\n",
    "    # Compute gradients\n",
    "    grad_gd = compute_gradient(x_gd)\n",
    "    grad_gdm = compute_gradient(x_gdm)\n",
    "\n",
    "    # Normal Gradient Descent Update\n",
    "    x_gd = x_gd - learning_rate * grad_gd\n",
    "    gd_trajectory.append(x_gd.numpy())\n",
    "\n",
    "    # Gradient Descent with Momentum Update\n",
    "    velocity = momentum * velocity - learning_rate * grad_gdm\n",
    "    x_gdm = x_gdm + velocity\n",
    "    gdm_trajectory.append(x_gdm.numpy())\n",
    "    \n",
    "    \n",
    "# Convert trajectories to NumPy for plotting\n",
    "gd_trajectory = np.array(gd_trajectory)\n",
    "gdm_trajectory = np.array(gdm_trajectory)\n",
    "\n",
    "# Create a meshgrid for 3D surface plot\n",
    "x1_vals = np.linspace(-10, 40, 100)\n",
    "x2_vals = np.linspace(-10, 10, 100)\n",
    "X1, X2 = np.meshgrid(x1_vals, x2_vals)\n",
    "Z = loss_function([X1,X2])\n",
    "\n",
    "# Plot the function surface and optimization paths\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 3D surface plot\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7)\n",
    "\n",
    "# Plot GD trajectory\n",
    "ax.plot(gd_trajectory[:, 0], gd_trajectory[:, 1], color='red', marker='o', markersize=4, label='Gradient Descent')\n",
    "\n",
    "# Plot GDM trajectory\n",
    "ax.plot(gdm_trajectory[:, 0], gdm_trajectory[:, 1], color='blue', marker='o', markersize=4, label='Momentum Gradient Descent')\n",
    "\n",
    "# Labels and legend\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('Loss')\n",
    "ax.set_title('Gradient Descent vs Momentum Gradient Descent')\n",
    "ax.legend()\n",
    "\n",
    "# 2D Contour plot projection\n",
    "ax.contour(X1, X2, Z, levels=20, cmap='gray', zdir='z', offset=np.min(Z))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Define the loss function f(x1, x2) = (x1 - 20)^2 / 20 + 2 * x2^2\n",
    "def loss_function(x):\n",
    "    return (x[0] - 20) ** 2 / 20 + 2 * x[1] ** 2\n",
    "\n",
    "# Gradient of the loss function\n",
    "def compute_gradient(x):\n",
    "    grad_x1 = 2 * (x[0] - 20) / 20\n",
    "    grad_x2 = 2 * 2 * x[1]\n",
    "    return torch.tensor([grad_x1, grad_x2])\n",
    "\n",
    "# Optimization settings\n",
    "learning_rate = 0.5\n",
    "momentum = 0.9\n",
    "iterations = 50\n",
    "\n",
    "# Initial points\n",
    "x_gd = torch.tensor([-5.0, -5.0])\n",
    "x_gdm = torch.tensor([-5.0, -5.0])\n",
    "\n",
    "# Lists to store trajectory for plotting\n",
    "gd_trajectory = [x_gd.numpy()]\n",
    "gdm_trajectory = [x_gdm.numpy()]\n",
    "\n",
    "# Momentum velocity term\n",
    "velocity = torch.tensor([0.0, 0.0])\n",
    "\n",
    "# Perform optimization\n",
    "for _ in range(iterations):\n",
    "    grad_gd = compute_gradient(x_gd)\n",
    "    grad_gdm = compute_gradient(x_gdm)\n",
    "\n",
    "    # Normal Gradient Descent Update\n",
    "    x_gd = x_gd - learning_rate * grad_gd\n",
    "    gd_trajectory.append(x_gd.numpy())\n",
    "\n",
    "    # Gradient Descent with Momentum Update\n",
    "    velocity = momentum * velocity - learning_rate * grad_gdm\n",
    "    x_gdm = x_gdm + velocity\n",
    "    gdm_trajectory.append(x_gdm.numpy())\n",
    "\n",
    "# Convert trajectories to NumPy for plotting\n",
    "gd_trajectory = np.array(gd_trajectory)\n",
    "gdm_trajectory = np.array(gdm_trajectory)\n",
    "\n",
    "# Create meshgrid for surface and contour plots\n",
    "x1_vals = np.linspace(-10, 40, 100)\n",
    "x2_vals = np.linspace(-10, 10, 100)\n",
    "X1, X2 = np.meshgrid(x1_vals, x2_vals)\n",
    "Z = loss_function([X1, X2])\n",
    "\n",
    "# Create figure and subplots\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 3D surface plot\n",
    "ax3d = fig.add_subplot(121, projection='3d')\n",
    "ax3d.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7)\n",
    "\n",
    "# 2D contour plot\n",
    "ax2d = fig.add_subplot(122)\n",
    "contour = ax2d.contour(X1, X2, Z, levels=30, cmap='viridis')\n",
    "ax2d.clabel(contour, inline=True, fontsize=8)\n",
    "\n",
    "# Initialize points for animation\n",
    "gd_point_3d, = ax3d.plot([], [], [], 'ro', markersize=8, label=\"Gradient Descent\")\n",
    "gdm_point_3d, = ax3d.plot([], [], [], 'bo', markersize=8, label=\"Momentum GD\")\n",
    "\n",
    "gd_point_2d, = ax2d.plot([], [], 'ro', markersize=8)\n",
    "gdm_point_2d, = ax2d.plot([], [], 'bo', markersize=8)\n",
    "\n",
    "# Plot initial trajectories\n",
    "gd_traj_2d, = ax2d.plot([], [], 'r-', alpha=0.5)\n",
    "gdm_traj_2d, = ax2d.plot([], [], 'b-', alpha=0.5)\n",
    "\n",
    "# Labels and legends\n",
    "ax3d.set_xlabel('$x_1$')\n",
    "ax3d.set_ylabel('$x_2$')\n",
    "ax3d.set_zlabel('Loss')\n",
    "ax3d.set_title('Gradient Descent vs Momentum (3D Surface)')\n",
    "ax3d.legend()\n",
    "\n",
    "ax2d.set_xlabel('$x_1$')\n",
    "ax2d.set_ylabel('$x_2$')\n",
    "ax2d.set_title('Optimization Path on Contour')\n",
    "\n",
    "def update(frame):\n",
    "    if frame < len(gd_trajectory):\n",
    "        # Update ball positions (must pass lists or arrays, not scalars)\n",
    "        gd_point_3d.set_data([gd_trajectory[frame, 0]], [gd_trajectory[frame, 1]])\n",
    "        gd_point_3d.set_3d_properties([loss_function(gd_trajectory[frame])])\n",
    "\n",
    "        gdm_point_3d.set_data([gdm_trajectory[frame, 0]], [gdm_trajectory[frame, 1]])\n",
    "        gdm_point_3d.set_3d_properties([loss_function(gdm_trajectory[frame])])\n",
    "\n",
    "        gd_point_2d.set_data([gd_trajectory[frame, 0]], [gd_trajectory[frame, 1]])\n",
    "        gdm_point_2d.set_data([gdm_trajectory[frame, 0]], [gdm_trajectory[frame, 1]])\n",
    "\n",
    "        # Update trajectory lines on contour plot\n",
    "        gd_traj_2d.set_data(gd_trajectory[:frame+1, 0], gd_trajectory[:frame+1, 1])\n",
    "        gdm_traj_2d.set_data(gdm_trajectory[:frame+1, 0], gdm_trajectory[:frame+1, 1])\n",
    "\n",
    "    return gd_point_3d, gdm_point_3d, gd_point_2d, gdm_point_2d, gd_traj_2d, gdm_traj_2d\n",
    "\n",
    "# Create and save animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=iterations, interval=150, blit=True)\n",
    "\n",
    "# Save the animation as a GIF file\n",
    "gif_filename = \"./img/gradient_vs_momentum.gif\"\n",
    "ani.save(gif_filename, writer=animation.PillowWriter(fps=10))\n",
    "\n",
    "print(f\"Animation saved as {gif_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## That's it for today\n",
    "\n",
    "We'll discuss linear regression next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other References: \n",
    " \n",
    "[1] Dimitrios Katselis \"Lecture 3: Steepest and Gradient Descent-Part I\" [link](https://katselis.web.engr.illinois.edu/ECE586/Lecture3.pdf)\n",
    "\n",
    "[2] Lewis Mitchell, \"Gradient descent: steepest descent\" [video](https://www.youtube.com/watch?v=8hau2T9bghA)\n",
    "\n",
    "[3] Visually Explained, \"Accelerate Gradient Descent with Momentum\" [video](https://www.youtube.com/watch?v=iudXf5n_3ro&t=60s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
