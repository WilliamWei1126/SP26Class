{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img align=\"left\" src=\"img/ECE364-logo.png\" width=\"300px\" style=\"padding:30px;border:thin solid white;\"> \n",
    "\n",
    "# Lecture 5 - Gradient Descent\n",
    "## ECE364 - Programming Methods for Machine Learning\n",
    "### Nickvash Kani \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Slides based off prior lectures by Alex Schwing, Aigou Han, Farzas Kamalabadi, Corey Snyder. All mistakes are my own!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In today's lecture: Gradient Descent!\n",
    "\n",
    "- Motivation behind gradient descent\n",
    "- One dimensional gradient descent\n",
    "- Loss functions\n",
    "- Fitting function to data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most of machine learning focuses on finding the minimum value of a function. The reason why this is the case will be discussed later in the lecture. \n",
    "\n",
    "But for now, here's the deal, we need to find the input values for which $f$ is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For simple functions this couldn't be easier: \n",
    "\n",
    "- $f=sin(x)$ - minimized at $f=-1$ where $x=\\frac{3}{2}\\pi$\n",
    "- $f= ax^2 + bx + c$ - $f$ minimized at $x = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$ if $a$ is positive, otherwise minimized a $x = \\pm \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For other functions, seems a bit harder:\n",
    "\n",
    "- $f(x) = \\frac{1}{3}(x-1)^6-(x-2)^5+5x^4.$ $f=0$ at $x=?$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's graph and see what we get: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 2, 1000)\n",
    "f_x = (1/3)*(x-1)**6-(x-2)**5+5*x**4\n",
    "plt.figure()\n",
    "plt.plot(x, f_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How do we find the minima? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Methods to find minimum value:\n",
    "\n",
    "- Iteratively? - guess an inital value for x and follow the curve until you reach the minima? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function\n",
    "def f_x(x):\n",
    "    return (1/3)*(x-1)**6 - (x-2)**5 + 5*x**4\n",
    "\n",
    "# Iterative search parameters\n",
    "x_start = 1.7  # Initial x value\n",
    "delta = 0.25  # Initial step size\n",
    "tolerance = 1e-5  # Convergence criterion\n",
    "x_vals = [x_start]  # Store visited points\n",
    "f_vals = [f_x(x_start)]\n",
    "\n",
    "# Iterative search for the minimum\n",
    "x = x_start\n",
    "while True:\n",
    "    x_next = x + delta\n",
    "    f_current = f_x(x)\n",
    "    f_next = f_x(x_next)\n",
    "\n",
    "    if f_next > f_current:  # If function value increases, reduce step size and reverse direction\n",
    "        delta = -delta / 2\n",
    "\n",
    "    x = x_next\n",
    "    x_vals.append(x)\n",
    "    f_vals.append(f_x(x))\n",
    "\n",
    "    # Check for convergence\n",
    "    if abs(delta) < tolerance:\n",
    "        break\n",
    "\n",
    "# Generate plot data\n",
    "x_range = np.linspace(0, 2, 400)\n",
    "y_range = f_x(x_range)\n",
    "\n",
    "# Plot the function\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_range, y_range, 'b-', label=\"Function $f(x)$\")  # Function in blue\n",
    "plt.plot(x_vals, f_vals, 'ro-', label=\"Iterative search\")  # Search path in red with dots\n",
    "\n",
    "# Set x and y limits\n",
    "plt.xlim(-0.1, 2.1)\n",
    "plt.ylim(0, 85)\n",
    "\n",
    "# Ensure full box around the graph\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.gca().spines['bottom'].set_visible(True)\n",
    "plt.gca().spines['left'].set_visible(True)\n",
    "\n",
    "# Show the plot\n",
    "plt\n",
    "\n",
    "print(x_vals[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Problems with iterative method: \n",
    "\n",
    "- Dependent on x starting value \n",
    "    - if you chose x=100,  god help you\n",
    "- Choosing the wrong initial increment can make things even worse and cause you to overshoot the minima\n",
    "\n",
    "Would be nice if we can adjust increment as we get closer to the minima..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice the slope gets smaller the closer we get to the minima. This makes sense because we know th minima occurs when $ \\frac{df}{dx} = 0$. Maybe we can use the derivative to scale our iteration inverval? This is known as **gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "\n",
    "- We know the gradient (and by analogy the derivative) points in the direction of steepest ascent\n",
    "    - if we would like to minimize our function we should step in the direction of the negative gradient. \n",
    "\n",
    "- Suppose we have a differentiable function $f(x)$ that we would like to minimize but cannot find a closed form solution for the minimum. \n",
    "    - we will initialize a guess for the minimum, denoted as $x^{(0)}$. We will then update $x$ to the next guess by moving its value opposite of the gradient to $x^{(1)}$ and so on until the gradient is zero or sufficiently close to zero. Formally, we will iterate the following **gradient descent update equation**\n",
    "\n",
    "$$\n",
    "x^{(k+1)}=x^{(k)}-\\alpha \\nabla f(x).\n",
    "$$\n",
    "\n",
    "- Above, $\\alpha >0$ is known as the **step-size** for gradient descent and controls how big our steps are in the direction of the negative gradient (more on selecting $\\alpha$ in future lectures!). Note also that we are using the gradient notation even for single variable functions to generalize to when we consider the multivariable case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's return to our prior function: \n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{3}(x-1)^6-(x-2)^5+5x^4.\n",
    "$$\n",
    "\n",
    "The derivative is then given by\n",
    "$$\n",
    "\\frac{df}{dx} = 2(x-1)^5-5(x-2)^4+20x^3.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Apply gradient descent to the previous complicated function to approximate the value of $x$ that minimizes $f(x)$. For convenience:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    f(x) &= \\frac{1}{3}(x-1)^6-(x-2)^5+5x^4\\\\\n",
    "    \\frac{df}{dx} &= 2(x-1)^5-5(x-2)^4+20x^3\\\\\n",
    "    x^{(k+1)} &= x^{(k)}-\\alpha\\nabla f(x).\n",
    "\\end{align*}\n",
    "$$\n",
    "Use a starting point of $x^{(0)}=0$ and $\\alpha=10^{-3}$. Run gradient descent for 100 iterations, plot the values of $x^{(k)}$, and the magnitude of the gradient at each iteration.\n",
    "\n",
    "**Bonus: try varying the initial value of $x$ and choice of $\\alpha$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return (1/3)*(x-1)**6 - (x-2)**5 + 5*x**4\n",
    "    \n",
    "n_iter = 100 # number of iterations\n",
    "x_init = 1.7 # initial guess for x\n",
    "alpha = 1e-3 # step size, 10**-3\n",
    "x_values = [x_init]\n",
    "x = x_init\n",
    "gradients = []\n",
    "for n in range(n_iter):\n",
    "    # calculate gradient\n",
    "    gradient = 2*(x-1)**5 - 5*(x-2)**4 + 20*x**3\n",
    "    # perform gradient descent step to obtain next value\n",
    "    x_next = x - alpha*gradient\n",
    "    # store values of x and gradient\n",
    "    x_values.append(x_next)\n",
    "    gradients.append(gradient)\n",
    "    # update x for next step\n",
    "    x = x_next\n",
    "\n",
    "x_range = np.linspace(0, 2, 400)    \n",
    "# plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x_range, f(x_range), 'royalblue')\n",
    "plt.plot(np.array(x_values), f(np.array(x_values)), 'ro-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.grid(True)\n",
    "plt.subplot(223)\n",
    "plt.plot(np.arange(len(x_values)), x_values, 'forestgreen')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Value of x')\n",
    "plt.grid(True)\n",
    "plt.subplot(224)\n",
    "plt.semilogy(np.arange(n_iter), np.abs(gradients), 'royalblue')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Magnitude of gradient')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Much more can be shown about gradient descent including variations on gradient descent, convergence guarantees, convergence rates, and more. For the purposes of this course, we primarily need to motivate the use of gradient descent for machine learning problems and other interesting details are best left to ECE 490: Introduction to Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Drawback #1\n",
    "\n",
    "Gradient descent isn't perfect. It can get stuck in a local minima. To demonstrate this point, let's return to our complex equation from the prior lectures: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$e(x) = x^2$, $g(e) = e+1$, $h(g) = \\log(g)$, $k(h) = \\sin(h)$. Thus, $f(x) = k(h(g(x)))$\n",
    "\n",
    "The resulting function is: $$f(x) = \\sin(\\log(((x)^2+1)))$$\n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"img/comp_graph_example_1d_2.png\" width=\"1000px\" style=\"padding:30px;border:thin solid white;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\frac{df}{dx} = \\left.\\frac{dk}{dh}\\right|_{h(g)} \\cdot \\left.\\frac{dh}{dg}\\right|_{g(x)} \\cdot \\left.\\frac{dg}{de}\\right|_{e(x)} \\cdot \\left.\\frac{de}{dx}\\right|_x$$\n",
    "\n",
    "$$\\frac{df}{dx} = \\cos(h(g)) \\cdot \\frac{1}{g(x)} \\cdot 1 \\cdot 2x = \\cos(\\log(x^2+1)) \\cdot \\frac{1}{x^2+1} \\cdot 2x= \\frac{2x\\cos(\\log(x^2+1))}{x^2+1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-20, 20, 1000)\n",
    "f_x = np.sin(np.log(x**2 + 1))\n",
    "plt.figure()\n",
    "plt.plot(x, f_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's find the minima of the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(np.log(x**2+1))\n",
    "    \n",
    "n_iter = 100 # number of iterations\n",
    "x_init = 1.7 # initial guess for x\n",
    "#x_init = 2.5 # initial guess for x\n",
    "alpha = 1e-3 # step size, 10**-3\n",
    "x_values = [x_init]\n",
    "x = x_init\n",
    "gradients = []\n",
    "for n in range(n_iter):\n",
    "    # calculate gradient\n",
    "    gradient = 2*x*np.cos(np.log(x**2+1))/(x**2+1)\n",
    "    # perform gradient descent step to obtain next value\n",
    "    x_next = x - alpha*gradient\n",
    "    # store values of x and gradient\n",
    "    x_values.append(x_next)\n",
    "    gradients.append(gradient)\n",
    "    # update x for next step\n",
    "    x = x_next\n",
    "\n",
    "#print(x_values)\n",
    "x_range = np.linspace(-20, 20, 400)    \n",
    "# plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x_range, f(x_range), 'royalblue')\n",
    "plt.plot(np.array(x_values), f(np.array(x_values)), 'ro-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic Differentiation\n",
    "\n",
    "The optimization above had one big drawback, I had to hand calculate the gradients symbolically and enter in the correct values. But what I can't do that for all math functiond and unfortunately,  we must develop an efficient and exact method for computing gradients automatically for arbitrarily complicated functions. There are a few options:\n",
    "\n",
    "* Numeric differentiation, i.e. finite differences: choose a suitably small value of $h$ to approximate $f'(x)$.\n",
    "  $$\n",
    "  \\frac{df}{dx} = \\underset{h\\to 0}{\\textrm{lim}}~\\frac{f(x+h)-f(x)}{h}\n",
    "  $$\n",
    "\n",
    "\n",
    "* Symbolic differentiation: compose derivatives/gradients in symbolic closed-form using simple rules, i.e. chain rule. Evaluate this expression to compute gradients.\n",
    "\n",
    "* Backpropagation: construct a computational graph of a function and use simple derivative/gradient rules to evaluate small pieces of the gradient and accumulate results via chain rule. (**This is what we will use!**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objective Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we do **not** want to calculate a minima. Let's say we want to know for what value of $x$ the prior function $f=0.5$. \n",
    "\n",
    "Well to do that, we need to change our optimization by defining a new **objective function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The simplest version of an optimization problem may be stated as follows:\n",
    "$$\n",
    "\\underset{x}{\\min}f(x).\n",
    "$$\n",
    "The above expression gives an unconstrained optimization problem, i.e. no constraints on values $x$ can attain, where we look to find $x$ that minimizes the given **objective function** $f(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But again, that will just give us the walue of $x$ where the whole thing evaluates to 0. **I want to know when the function evaluates to 0.5!** \n",
    "\n",
    "One way to do this is to wrap this function ($f(x)$) up in a new  that is smallest when $f(x)=0.5$. \n",
    "\n",
    "And the clever trick we can do is write a new function that take $y_i$ as a input and makes it with our desired output. One highly popular choice is **mean squared error** (MSE). \n",
    "$$\n",
    "\\ell_{\\textrm{mse}}=(y-f(x))^2.\n",
    "$$\n",
    "The intuition for squaring the errors, $y_i-f(x_i)$, is that we want positive and negative errors to be treated the same.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So let's try an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's try our someplex function from above: \n",
    "\n",
    "$$f(x) = \\sin(\\log(((x)^2+1)))$$\n",
    "\n",
    "but this time let's add another layer to it and say the loss\n",
    "\n",
    "$$\n",
    "\\ell_{\\textrm{mse}}=(0.5-f(x))^2.\n",
    "$$\n",
    "\n",
    "and the gradient for this function would be: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x}\\ell_{\\textrm{mse}}=2\\dot(0.5-f(x))\\cdot\\frac{\\partial f(x)}{\\partial x}.\n",
    "$$\n",
    "\n",
    "\n",
    "Code would look something like: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(np.log(x**2+1))\n",
    "    \n",
    "n_iter = 100 # number of iterations\n",
    "x_init = 1.7 # initial guess for x\n",
    "#x_init = 2.5 # initial guess for x\n",
    "alpha = 100e-3 # step size, 10**-3\n",
    "x_values = [x_init]\n",
    "x = x_init\n",
    "gradients = []\n",
    "for n in range(n_iter):\n",
    "    # calculate gradient\n",
    "    gradient = 2*(0.5-f(x))*-1*2*x*np.cos(np.log(x**2+1))/(x**2+1)\n",
    "    # perform gradient descent step to obtain next value\n",
    "    x_next = x - alpha*gradient\n",
    "    # store values of x and gradient\n",
    "    x_values.append(x_next)\n",
    "    gradients.append(gradient)\n",
    "    # update x for next step\n",
    "    x = x_next\n",
    "\n",
    "#print(x_values)\n",
    "x_range = np.linspace(-20, 20, 400)    \n",
    "# plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x_range, f(x_range), 'royalblue')\n",
    "plt.plot(np.array(x_values), f(np.array(x_values)), 'ro-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimating parameters to match multiple data values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider the problem of finding the parameters which make a particular equation best fit soem collection of data. We may accomplish by first posing a reasonable optimization problem. Suppose we refer to our dataset $\\mathcal{D}=\\{(x_i, y_i)\\}_{i=1}^{N}$ as $N$ tuples of inputs and outputs. For a given guess of set of parameters, the function will produce $f(x_i)$ while the correct or **ground-truth** value $y_i$ may be different. Thus, for current values of $(a, b, c)$, we have some amount of error. We need a reasonable objective function to minimize these errors with respect to this dataset. We can take the mean (average) of the sum of squared errors over the dataset. Let $\\ell_{\\textrm{mse}}(\\mathcal{D})$ denote the MSE over the dataset.\n",
    "$$\n",
    "\\ell_{\\textrm{mse}}=\\frac{1}{N}\\sum_{i=1}^{N}(y_i-f(x_i))^2.\n",
    "$$\n",
    "The intuition for squaring the errors, $y_i-f(x_i)$, is that we want positive and negative errors to be treated the same. We now have all the elements of a well-posed optimization problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Alertness check:** What is the function represented by the following computation graph: \n",
    "\n",
    "<div>\n",
    "<center><img src=\"img/quadratic-regression-graph.png\" width=\"1000\"/> </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For just one data point, we can perform the forward pass to calculate values at each node, i.e. $ax^2$, $bx$, $\\ell_{\\textrm{mse}}(x_i, y_i)$. Then, we initiate backpropagation from the seed node to automatically compute the gradient of the loss function with respect to each parameter, i.e. $\\frac{\\partial \\ell_{\\textrm{mse}}}{\\partial a}, \\frac{\\partial \\ell_{\\textrm{mse}}}{\\partial b}, \\frac{\\partial \\ell_{\\textrm{mse}}}{\\partial c}$. For completeness, we can easily derive these partial derivatives from the computational graph.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial \\ell_{\\textrm{mse}}}{\\partial w_7} &= 1 & \\frac{\\partial w_7}{\\partial w_6} &= 2(w_6-w_5)\\\\\n",
    "    \\frac{\\partial w_7}{\\partial w_5} &= -2(w_6-w_5) & \\frac{\\partial w_5}{\\partial w_4} &= 1\\\\\n",
    "    \\frac{\\partial w_5}{\\partial w_3} &= 1 & \\frac{\\partial w_5}{\\partial c} &= 1\\\\\n",
    "    \\frac{\\partial w_4}{\\partial b} &=w_1 & \\frac{\\partial w_4}{\\partial w_1} &=b\\\\\n",
    "    \\frac{\\partial w_3}{\\partial a} &=w_2 & \\frac{\\partial w_3}{\\partial w_2} &=a\\\\\n",
    "    \\frac{\\partial w_2}{\\partial w_1} &=2w_1\n",
    "\\end{align*}\n",
    "\n",
    "And finally, the adjoints:\n",
    "\\begin{align*}\n",
    "    \\bar{w}_7 &= \\frac{\\partial \\ell_{\\textrm{mse}}}{\\partial w_7}\\\\\n",
    "    \\bar{w}_5 &= \\bar{w}_7\\frac{\\partial w_7}{\\partial w_5} = -2(w_6-w_5) &\\bar{c} &= \\bar{w}_5\\frac{\\partial w_5}{c} = -2(w_6-w_5)\\\\\n",
    "    \\bar{w}_4 &= \\bar{w}_5\\frac{\\partial w_5}{\\partial w_4} = -2(w_6-w_5) &\\bar{w}_3 &= \\bar{w}_5\\frac{\\partial w_5}{\\partial w_3} = -2(w_6-w_5)\\\\\n",
    "    \\bar{b} &= \\bar{w}_4\\frac{\\partial w_4}{\\partial b} = -2w_1(w_6-w_5) &\\bar{a} &= \\bar{w}_3\\frac{\\partial w_3}{\\partial a} = -2w_2(w_6-w_5)\n",
    "\\end{align*}\n",
    "\n",
    "Note that we do not give $\\bar{w}_6$, $\\bar{w}_1$, and $\\bar{w}_2$ since they are not necessary for this problem for deriving the partial derivatives with respect to $a$, $b$, and $c$. The above quantities give the result of backpropagation for one data point. However, we have a dataset of $N$ points, so how can we perform backpropagation across the whole dataset? We can just add the gradients due to each input-output pair! Differentiation is linear; thus, gradient of the entire objective with respect to $a$, $b$, and $c$ is the sum of the gradients for each entry in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Manually performing gradient descent works, but we don't want to have to type expressions for partial derivatives for every parameter especially when the number of parameters grows to hundreds, thousands, or millions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining Gradient Descent and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Recall from the first part of our autodifferentiation lectures that gradient descent for a given optimization problem proceeds as follows\n",
    "$$\n",
    "x^{(k+1)} = x^{(k)}-\\alpha\\nabla f(x)\n",
    "$$\n",
    "for step size $\\alpha$ at iteration $k$. Now in the above example, we have a function with one input, but three parameters for which we are computing the gradient. Let $\\theta=\\{a, b, c\\}$ represent these three parameters as a vector. We can thus write our gradient descent update equation instead as\n",
    "$$\n",
    "\\theta^{(k+1)} = \\theta^{(k)}-\\alpha\\nabla_\\theta f(x),\n",
    "$$\n",
    "where the use of this $\\theta$ notation implies the following three equations:\n",
    "$$\n",
    "\\begin{align*}\n",
    "a^{(k+1)} &= a^{(k)}-\\alpha\\frac{\\partial f(x)}{\\partial a}\\\\\n",
    "b^{(k+1)} &= b^{(k)}-\\alpha\\frac{\\partial f(x)}{\\partial b}\\\\\n",
    "c^{(k+1)} &= c^{(k)}-\\alpha\\frac{\\partial f(x)}{\\partial c}.\n",
    "\\end{align*}\n",
    "$$\n",
    "The above notation is often used in machine learning applications where a variable like $\\theta$ is used to collect all trainable or learnable parameters as shorthand for gradient descent. Similarly, you may also see notation like $f(x;\\theta)$ where the semi-colon distinguishes between inputs like $x$ and parameters of the function $\\theta$.\n",
    "\n",
    "Even without our knowledge of backpropagation or PyTorch, we could apply gradient descent to the above example since the partial derivatives are fairly easy to find by hand.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial\\ell_{\\textrm{mse}}(f(x_i), y_i)}{\\partial a} &= -2x_i^2(y_i-ax_i^2-bx_i-c)\\\\\n",
    "    \\frac{\\partial\\ell_{\\textrm{mse}}(f(x_i), y_i)}{\\partial b} &= -2x_i(y_i-ax_i^2-bx_i-c)\\\\\n",
    "    \\frac{\\partial\\ell_{\\textrm{mse}}(f(x_i), y_i)}{\\partial c} &= -2(y_i-ax_i^2-bx_i-c)\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# values we are trying to regress, pretend we don't know them!\n",
    "a = 3\n",
    "b = 2\n",
    "c = 1\n",
    "\n",
    "# generate dataset\n",
    "N = 20 # number of data points\n",
    "x = np.linspace(-2, 2, N)\n",
    "y = a*x**2 + b*x + c\n",
    "\n",
    "# initialize guesses for a, b, and c\n",
    "a_gd = np.random.randn()\n",
    "b_gd = np.random.randn()\n",
    "c_gd = np.random.randn()\n",
    "print('Initial guesses: a={:.6f}, b={:.6f}, c={:.6f}'.format(a_gd, b_gd, c_gd))\n",
    "\n",
    "# information for tracking\n",
    "a_vals = [a_gd]\n",
    "b_vals = [b_gd]\n",
    "c_vals = [c_gd]\n",
    "loss_vals = []\n",
    "\n",
    "# gradient descent loop\n",
    "n_iter = 100 # number of iterations\n",
    "alpha = 1e-2 # step size\n",
    "for n in range(n_iter):\n",
    "    # let numpy broadcasting compute all partials across the dataset\n",
    "    errors = y-(a_gd*x**2 + b_gd*x + c_gd)\n",
    "    partial_a = np.sum(-2*x**2*errors)/N\n",
    "    partial_b = np.sum(-2*x*errors)/N\n",
    "    partial_c = np.sum(-2*errors)/N\n",
    "    # perform gradient descent update step\n",
    "    a_gd = a_gd - alpha*partial_a\n",
    "    b_gd = b_gd - alpha*partial_b\n",
    "    c_gd = c_gd - alpha*partial_c\n",
    "    # log information\n",
    "    loss_vals.append(np.sum(errors**2)/N) # log MSE\n",
    "    a_vals.append(a_gd)\n",
    "    b_vals.append(b_gd)\n",
    "    c_vals.append(c_gd)\n",
    "\n",
    "# examine solution\n",
    "print('Final guesses: a={:.6f}, b={:.6f}, c={:.6f}'.format(a_vals[-1], b_vals[-1], c_vals[-1]))\n",
    "\n",
    "# visualize loss and progression of solution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(loss_vals, color='blue')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('MSE value for regression')\n",
    "\n",
    "iter_num = np.array([0, 5, 25, 50, 100]).astype(int)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "for j, i in enumerate(iter_num):\n",
    "    plt.subplot(1, 5, j+1)\n",
    "    curr_fn = a_vals[i]*x**2 + b_vals[i]*x + c_vals[i]\n",
    "    plt.plot(x, curr_fn, color='blue')\n",
    "    plt.scatter(x, y, color='orange')\n",
    "    plt.grid(True)\n",
    "    plt.title('Regressed function: Iteration {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using PyTorch Autograd\n",
    "\n",
    "We have briefly explored the PyTorch Autograd engine in previous lectures thus far. Now, we want to utilize it to automatically perform backpropagation for us and make gradient descent much more scalable!\n",
    "\n",
    "Let's start by showing how the previous example can be converted from Numpy to PyTorch code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# values we are trying to regress, pretend we don't know them!\n",
    "a = 3\n",
    "b = 2\n",
    "c = 1\n",
    "\n",
    "# generate dataset\n",
    "N = 20 # number of data points\n",
    "x = torch.linspace(-2, 2, N)\n",
    "y = a*x**2 + b*x + c\n",
    "\n",
    "# initialize guesses for a, b, and c\n",
    "a_gd = torch.randn((), requires_grad=True) # size (1,)\n",
    "b_gd = torch.randn((), requires_grad=True)\n",
    "c_gd = torch.randn((), requires_grad=True)\n",
    "print('Initial guesses: a={:.6f}, b={:.6f}, c={:.6f}'.format(a_gd.data, b_gd.data, c_gd.data))\n",
    "\n",
    "# information for tracking\n",
    "a_vals = [a_gd.data.item()]\n",
    "b_vals = [b_gd.data.item()]\n",
    "c_vals = [c_gd.data.item()]\n",
    "loss_vals = []\n",
    "\n",
    "# gradient descent loop\n",
    "n_iter = 100 # number of iterations\n",
    "alpha = 1e-2 # step size\n",
    "for n in range(n_iter):\n",
    "    # compute loss function (objective function)\n",
    "    errors = y-(a_gd*x**2 + b_gd*x + c_gd)\n",
    "    loss = torch.sum((errors)**2)/N\n",
    "    # backpropagate gradients\n",
    "    loss.backward()\n",
    "    # perform gradient descent update step\n",
    "    with torch.no_grad():\n",
    "        # don't want the gradient update step to accumulate further gradients at a, b, and c\n",
    "        a_gd -= alpha*a_gd.grad\n",
    "        b_gd -= alpha*b_gd.grad\n",
    "        c_gd -= alpha*c_gd.grad\n",
    "        # manually zero out the gradients before next backward pass\n",
    "        a_gd.grad = None\n",
    "        b_gd.grad = None\n",
    "        c_gd.grad = None\n",
    "        \n",
    "    # log information\n",
    "    loss_vals.append(loss.item()) # log MSE\n",
    "    a_vals.append(a_gd.data.item())\n",
    "    b_vals.append(b_gd.data.item())\n",
    "    c_vals.append(c_gd.data.item())\n",
    "\n",
    "# examine solution\n",
    "print('Final guesses: a={:.6f}, b={:.6f}, c={:.6f}'.format(a_vals[-1], b_vals[-1], c_vals[-1]))\n",
    "\n",
    "# visualize loss and progression of solution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(loss_vals, color='blue')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('MSE value for regression')\n",
    "\n",
    "iter_num = np.array([0, 5, 25, 50, 100]).astype(int)\n",
    "plt.figure(figsize=(20, 5))\n",
    "for j, i in enumerate(iter_num):\n",
    "    plt.subplot(1, 5, j+1)\n",
    "    curr_fn = a_vals[i]*x**2 + b_vals[i]*x + c_vals[i]\n",
    "    plt.plot(x.detach().numpy(), curr_fn.detach().numpy(), color='blue')\n",
    "    plt.scatter(x.detach().numpy(), y, color='orange')\n",
    "    plt.grid(True)\n",
    "    plt.title('Regressed function: Iteration {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A few notes to the above implementation:\n",
    "\n",
    "* ``requires_grad=True``: Recall that we set this attribute to True when we would like to access gradients for the given tensor. In this case, we wanted gradients for tensors ``a_gd``, ``b_gd``, and ``c_gd`` since they are our parameters of interest.\n",
    "* ``.data.item()``: The ``.data`` attribute accesses only the data in the tensor, but still returns a tensor. If we want just the numerical data outside of the tensor data structure, we need to also call the ``.item()`` method.\n",
    "* ``torch.no_grad()``: The ``torch.no_grad()`` method specifies that no computation within its scope will alter gradients within a computational graph. In our above example, we do not want the gradient descent update step to affect the gradients we already backpropagated. This is also why we used ``-=`` instead of ``a_gd = a_gd - ...`` since this would remove the ``requires_grad`` from each tensor.\n",
    "* Setting gradients to ``None``: The gradients at each node in the graph remain there until they are cleared. Thus, we need to remove them by setting each to ``None`` before the next backpropagation pass.\n",
    "* ``detach.numpy()``: The tensor ``x`` belongs to computational graph that require gradients. We must first detach these tensors from the computational graph if we intend to convert them to NumPy arrays for plotting. Alternatively, we could wrap our plotting in a ``torch.no_grad()`` statement.\n",
    "\n",
    "Some of these above points, e.g. specifying every Tensor that needs gradients, setting gradients to ``None``, and even applying the gradient descent step to every parameters, may seem tedious. And that's okay! In later lectures, we will show how the ``nn.Module`` class and ``torch.optim`` module greatly simplify code like above to only require a few lines instead of around a dozen.\n",
    "\n",
    "For now, we have successfully used PyTorch and its auto-differentiation engine to perform our first machine learning problem! Let's conclude this lecture with another example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One more function fit for the road?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recall from an earlier lecture where we introduced the sigmoid function $\\sigma(x)$:\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}.\n",
    "$$\n",
    "We extended sigmoid in one lecture exercise to have a different center point, i.e. where $\\sigma(x)=0.5$, and a sharper/smoother transition. Consider this augmented sigmoid function as $\\tilde{\\sigma}(x)$:\n",
    "$$\n",
    "\\tilde{\\sigma}(x) = \\frac{1}{1+\\exp{\\{-\\frac{x-b}{\\tau}}\\}},\n",
    "$$\n",
    "where $b$ and $\\tau$ give the center point and shape parameter, respectively. For this exercise, we would will use PyTorch, backpropagation, and gradient descent to automatically determine the $b$ and $\\tau$ values of a mystery sigmoid function. We can again use mean squared error to minimize the following objective function over dataset $\\mathcal{D}=\\{(x_i, y_i)\\}$ where each $y_i$ is generated from a mystery sigmoid function $\\tilde{\\sigma}(x_i)$.\n",
    "$$\n",
    "\\underset{b, \\tau}{\\min}~\\frac{1}{N}\\sum_{i=1}^{N}(y_i-f(x_i;b,\\tau))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's generate some datapoitns we want to fit to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \"unknown\" parameters we are trying to uncover\n",
    "b = -0.75\n",
    "tau = 2.25\n",
    "\n",
    "# create dataset\n",
    "N = 30 # number of datapoints\n",
    "x = torch.linspace(-10, 10, N)\n",
    "y = 1/(1+torch.exp(-(x-b)/tau))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Generate an inital guess of the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# part (a) initialize parameters\n",
    "b_gd = torch.randn((), requires_grad=True)\n",
    "tau_gd = torch.rand((), requires_grad=True) # tau_gd = torch.tensor([0.2], requires_grad=True)\n",
    "print('Initial Guess: b={:.4f}, tau={:.4f}'.format(b_gd.data.item(), tau_gd.data.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The we go through the backpropagation process: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# part (b) gradient descent loop\n",
    "n_iter = 500\n",
    "alpha = 1e0\n",
    "b_vals = [b_gd.data.item()]\n",
    "tau_vals = [tau_gd.data.item()]\n",
    "\n",
    "for n in range(n_iter):\n",
    "    # compute function outputs\n",
    "    f_x = 1/(1+torch.exp(-(x-b_gd)/tau_gd))\n",
    "    # calculate loss and initiate backpropagation\n",
    "    loss = torch.mean((y-f_x)**2) # same as torch.sum((y-f_x)**2)/N\n",
    "    loss.backward()\n",
    "    # update parameters by gradient descent\n",
    "    with torch.no_grad():\n",
    "        # gradient step\n",
    "        b_gd -= alpha*b_gd.grad\n",
    "        tau_gd -= alpha*tau_gd.grad\n",
    "        # set gradients to None\n",
    "        b_gd.grad = None\n",
    "        tau_gd.grad = None\n",
    "    b_vals.append(b_gd.data.item())\n",
    "    tau_vals.append(tau_gd.data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final guesses\n",
    "print('Final Guess: b={:.4f}, tau={:.4f}'.format(b_gd.data.item(), tau_gd.data.item()))\n",
    "        \n",
    "# part (c) plotting solution\n",
    "plt.figure(figsize=(20, 10))\n",
    "with torch.no_grad():\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.scatter(x.numpy(), y.numpy(), color='orange')\n",
    "    f_x = 1/(1+torch.exp(-(x-b_gd)/tau_gd)) # fill in this line, apply your parameters to the input data in x\n",
    "    plt.plot(x.numpy(), f_x.numpy(), color='blue')\n",
    "    plt.grid(True)\n",
    "\n",
    "iter_num = np.array([0, 100, 200, 300, 400]).astype(int)\n",
    "for j, i in enumerate(iter_num):\n",
    "    plt.subplot(2, 5, 5+j+1)\n",
    "    curr_fn = 1/(1+torch.exp(-(x-b_vals[i])/tau_vals[i]))\n",
    "    plt.plot(x.detach().numpy(), curr_fn.detach().numpy(), color='blue')\n",
    "    plt.scatter(x.detach().numpy(), y, color='orange')\n",
    "    plt.grid(True)\n",
    "    plt.title('Regressed function: Iteration {}'.format(i))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## That's it for today\n",
    "\n",
    "- Have a good weekend\n",
    "- Remember HW2 is due Monday"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
